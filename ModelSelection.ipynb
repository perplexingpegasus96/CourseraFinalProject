{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix,roc_auc_score, recall_score, precision_score\n",
    "import matplotlib.pylab as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Считывание данных из файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainTable = pd.read_csv('train.csv')\n",
    "testTable = pd.read_csv('test.csv')\n",
    "holdoutTable = pd.read_csv('hold-out dataset.csv')\n",
    "\n",
    "testTable.drop(['ID'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Признаки с максимальной корреляцией из 1ой недели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#признаки с максимальной корреляцией с целевой переменной\n",
    "maxCorrFloatFeatures = ['Var153','Var38',\n",
    "                         'Var113','Var76','Var131','Var133','Var134','Var163','Var149','Var81','Var53',\n",
    "                         'Var98','Var111','Var28','Var126','Var123','Var83','Var132','Var50','Var35']\n",
    "\n",
    "maxCorrCatFeatures = ['Var192','Var216',\n",
    "                     'Var206','Var212','Var205','Var228','Var193','Var207','Var227','Var204','Var221',\n",
    "                     'Var210','Var218','Var226','Var197','Var225','Var211','Var195','Var219','Var194']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сделаем начальное преобразование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformData(df, numColumns = None, catColumns = None, encoder = 'OneHot', nanFillStrategy = 'zero', \n",
    "                  nrows = 'all objects', preprocessData = True, dataSample = 'withTarget'):\n",
    "    if nrows == 'all objects':\n",
    "        df = df.sample(n = len(df), random_state = 42)\n",
    "    else:\n",
    "        df = df.sample(n = nrows, random_state = 42)\n",
    "    \n",
    "    if preprocessData:\n",
    "        allNumColumns = list(df.select_dtypes(include=[np.float]).columns)\n",
    "        allCatColumns = list(df.select_dtypes(include=['object']).columns)\n",
    "        \n",
    "        if numColumns != None:\n",
    "            allNumColumns = numColumns\n",
    "        if catColumns != None:\n",
    "            allCatColumns = catColumns\n",
    "        \n",
    "        if dataSample == 'withTarget':\n",
    "            df = df[allNumColumns + allCatColumns + ['label']]\n",
    "        else:\n",
    "            df = df[allNumColumns + allCatColumns]\n",
    "        \n",
    "        if nanFillStrategy == 'zero':\n",
    "            df[allNumColumns] = df[allNumColumns].fillna(0)\n",
    "        elif nanFillStrategy == 'mean':\n",
    "            for col in allNumColumns:\n",
    "                nanCount = df[col].isnull().sum()\n",
    "                if nanCount == len(df):\n",
    "                    df[col] = df[col].fillna(0)\n",
    "                else:\n",
    "                    df[col] = df[col].fillna(df[col].mean())                                                         \n",
    "            \n",
    "        stdScaler = StandardScaler()\n",
    "        df[allNumColumns] = stdScaler.fit_transform(df[allNumColumns])\n",
    "        \n",
    "        df[allCatColumns] = df[allCatColumns].fillna('unknown')\n",
    "        if encoder == 'OneHot':\n",
    "            df = pd.get_dummies(df, columns = allCatColumns)\n",
    "        if encoder == 'LabelEncoder':\n",
    "            df[allCatColumns] = df[allCatColumns].apply(LabelEncoder().fit_transform)\n",
    "            \n",
    "        try:\n",
    "            label = df.pop('label')\n",
    "            df['label']=label \n",
    "        except KeyError:\n",
    "            pass\n",
    "        print ('table was transformed!')\n",
    "        return df\n",
    "    \n",
    "def featureUnion(*args):\n",
    "    return list(set.intersection(*map(set, args)))\n",
    "\n",
    "def returnWeightedTarget(array, weights):\n",
    "    return map(lambda x:weights[0] if x == -1 else weights[1], array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table was transformed!\n",
      "table was transformed!\n",
      "table was transformed!\n"
     ]
    }
   ],
   "source": [
    "trainSet = transformData(trainTable, encoder='LabelEncoder')\n",
    "testSet = transformData(testTable, encoder = 'LabelEncoder', dataSample='noTarget')\n",
    "holdoutSet = transformData(holdoutTable, encoder = 'LabelEncoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from 'C:\\Users\\swink_000\\Anaconda2\\lib\\site-packages\\matplotlib\\pyplot.pyc'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wIqEuKlrENnBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x47fe9c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 7)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv,scoring = 'roc_auc', n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "X, y = trainSet.iloc[:,:-1], trainSet['label']\n",
    "\n",
    "title = \"Learning Curves (Gradient Boosting)\"\n",
    "\n",
    "cv = StratifiedKFold(n_splits=7, shuffle = True)\n",
    "\n",
    "estimator = GradientBoostingClassifier(random_state = 42)\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику кросс-валидации видно, что кривая качества выходит на асимпототу(~0.72) начиная с 11к объектов выборки. Остановимся на этом количестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table was transformed!\n"
     ]
    }
   ],
   "source": [
    "trainSet = transformData(trainTable, encoder='LabelEncoder', nrows=11000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countBalancedClass(labelSet):\n",
    "    return compute_class_weight(class_weight = 'balanced', classes  = [-1,1], y = labelSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[7373    6]\n",
      " [ 615    6]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.50442435872\n",
      "****************************************************************\n",
      "Classification Report with weight distr = [1, 1]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.92      1.00      0.96      7379\n",
      "          1       0.50      0.01      0.02       621\n",
      "\n",
      "avg / total       0.89      0.92      0.89      8000\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[7276  103]\n",
      " [ 563   58]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.539719607303\n",
      "****************************************************************\n",
      "Classification Report with weight distr = [0.5, 2]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.93      0.99      0.96      7379\n",
      "          1       0.36      0.09      0.15       621\n",
      "\n",
      "avg / total       0.88      0.92      0.89      8000\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[6778  601]\n",
      " [ 425  196]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.617086308602\n",
      "****************************************************************\n",
      "Classification Report with weight distr = [0.5, 4]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.94      0.92      0.93      7379\n",
      "          1       0.25      0.32      0.28       621\n",
      "\n",
      "avg / total       0.89      0.87      0.88      8000\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[5666 1713]\n",
      " [ 266  355]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.669756669\n",
      "****************************************************************\n",
      "Classification Report with weight distr = [0.53972002023950072, 6.7940552016985141]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.77      0.85      7379\n",
      "          1       0.17      0.57      0.26       621\n",
      "\n",
      "avg / total       0.89      0.75      0.81      8000\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[4943 2436]\n",
      " [ 191  430]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.681152764329\n",
      "****************************************************************\n",
      "Classification Report with weight distr = [0.5, 8]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.67      0.79      7379\n",
      "          1       0.15      0.69      0.25       621\n",
      "\n",
      "avg / total       0.90      0.67      0.75      8000\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[4233 3146]\n",
      " [ 141  480]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.673300913351\n",
      "****************************************************************\n",
      "Classification Report with weight distr = [0.5, 10]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.97      0.57      0.72      7379\n",
      "          1       0.13      0.77      0.23       621\n",
      "\n",
      "avg / total       0.90      0.59      0.68      8000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "balancedClass = countBalancedClass(trainSet['label'])\n",
    "weigthList = [[1,1],\n",
    "              [0.5, 2],#4 times\n",
    "              [0.5, 4],#8 times\n",
    "             [balancedClass[0], balancedClass[1]],#12 times\n",
    "              [0.5,8],#16 times\n",
    "              [0.5,10]#20  times\n",
    "             ]\n",
    "\n",
    "for weight in weigthList:\n",
    "    clf = GradientBoostingClassifier(random_state = 42).fit(trainSet.iloc[:, :-1], trainSet['label'],\n",
    "                                sample_weight = returnWeightedTarget(list(trainSet['label']), weight))\n",
    "    preds = clf.predict(holdoutSet.iloc[:, :-1])\n",
    "    \n",
    "    print \"Confusion Matrix\"\n",
    "    print confusion_matrix(holdoutSet['label'], preds)\n",
    "    print '*' * 64\n",
    "    print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "    print '*' * 64\n",
    "    print \"Classification Report with weight distr = {0}\".format(weight)\n",
    "    print classification_report(holdoutSet['label'], preds)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остановимся на сбалансированном распределении весов классов при обучении на данной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4718 2661]\n",
      " [ 228  393]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.636116135816\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.95      0.64      0.77      7379\n",
      "          1       0.13      0.63      0.21       621\n",
      "\n",
      "avg / total       0.89      0.64      0.72      8000\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[1638 5741]\n",
      " [  43  578]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.57636907104\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.97      0.22      0.36      7379\n",
      "          1       0.09      0.93      0.17       621\n",
      "\n",
      "avg / total       0.91      0.28      0.35      8000\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[5938 1441]\n",
      " [ 373  248]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.602035981904\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.94      0.80      0.87      7379\n",
      "          1       0.15      0.40      0.21       621\n",
      "\n",
      "avg / total       0.88      0.77      0.82      8000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SamplingStrategies = [\n",
    "    RandomUnderSampler(ratio = 'majority', random_state=42),\n",
    "    SMOTE(random_state=42),\n",
    "    NearMiss(ratio = 'majority', version = 3, random_state=42)\n",
    "]\n",
    "\n",
    "for strategy in SamplingStrategies:\n",
    "    resampledX, resampledY = strategy.fit_sample(train.iloc[:, :-1], train['label'])\n",
    "    clf = GradientBoostingClassifier(random_state=42).fit(resampledX, resampledY)\n",
    "    preds = clf.predict(holdoutSet.iloc[:,:-1])\n",
    "    \n",
    "    print \"Confusion Matrix\"\n",
    "    print confusion_matrix(holdoutSet['label'], preds)\n",
    "    print '*' * 64\n",
    "    print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "    print '*' * 64\n",
    "    print \"Classification Report\"\n",
    "    print classification_report(holdoutSet['label'], preds)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование сэмплирования приводит к худшим результатам нежели распределение весов, поэтому будет использовать распределение весов в дальнейшем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero fill strategy\n",
      "table was transformed!\n",
      "table was transformed!\n",
      "Confusion Matrix\n",
      "[[4943 2436]\n",
      " [ 191  430]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.681152764329\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.67      0.79      7379\n",
      "          1       0.15      0.69      0.25       621\n",
      "\n",
      "avg / total       0.90      0.67      0.75      8000\n",
      "\n",
      "\n",
      "\n",
      "mean fill strategy\n",
      "table was transformed!\n",
      "table was transformed!\n",
      "Confusion Matrix\n",
      "[[5030 2349]\n",
      " [ 203  418]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.677386036319\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.68      0.80      7379\n",
      "          1       0.15      0.67      0.25       621\n",
      "\n",
      "avg / total       0.90      0.68      0.75      8000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nanFillsStrategy = ['zero', 'mean']\n",
    "\n",
    "for filling in nanFillsStrategy:\n",
    "    print \"{0} fill strategy\".format(filling)\n",
    "    trainSet = transformData(trainTable, encoder='LabelEncoder', nanFillStrategy=filling)\n",
    "    holdoutSet = transformData(holdoutTable, encoder='LabelEncoder', nanFillStrategy=filling)\n",
    "    \n",
    "    clf = GradientBoostingClassifier(random_state=42).fit(trainSet.iloc[:, :-1], trainSet['label'],\n",
    "                    sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "    preds = clf.predict(holdoutSet.iloc[:, :-1])\n",
    "    print \"Confusion Matrix\"\n",
    "    print confusion_matrix(holdoutSet['label'], preds)\n",
    "    print '*' * 64\n",
    "    print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "    print '*' * 64\n",
    "    print \"Classification Report\"\n",
    "    print classification_report(holdoutSet['label'], preds)\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table was transformed!\n",
      "table was transformed!\n",
      "Confusion Matrix\n",
      "[[3931 3448]\n",
      " [ 143  478]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.651227129956\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.53      0.69      7379\n",
      "          1       0.12      0.77      0.21       621\n",
      "\n",
      "avg / total       0.90      0.55      0.65      8000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSet = transformData(trainTable, encoder='OneHot', nanFillStrategy='mean', \n",
    "                         nrows = 11000, dataSample = 'withTarget')\n",
    "holdoutSet = transformData(holdoutTable, encoder='OneHot', nanFillStrategy='mean', \n",
    "                           dataSample='withTarget')\n",
    "trainLabel, holdoutSetLabel = trainSet['label'], holdoutSet['label']\n",
    "trainSet.drop(['label'], axis = 1, inplace = True)\n",
    "holdoutSet.drop(['label'], axis = 1, inplace = True)\n",
    "commonFeatures = featureUnion(list(trainSet.columns), list(holdoutSet.columns))\n",
    "trainSet, holdoutSet = trainSet[commonFeatures],holdoutSet[commonFeatures]\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42).fit(trainSet, trainLabel,\n",
    "        sample_weight = returnWeightedTarget(list(trainLabel), [0.5, 8]))\n",
    "preds = clf.predict(holdoutSet)\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSetLabel, preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSetLabel, preds))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSetLabel, preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table was transformed!\n",
      "table was transformed!\n",
      "Getting features with Lasso...\n",
      "Lasso Alpha 0.0676825173828\n",
      "Confusion Matrix\n",
      "[[7285   94]\n",
      " [ 617    4]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.496851185165\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.92      0.99      0.95      7379\n",
      "          1       0.04      0.01      0.01       621\n",
      "\n",
      "avg / total       0.85      0.91      0.88      8000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lasso Feature Selection\n",
    "def lassoStrategy(X, y):\n",
    "    selectedFeatures = []\n",
    "    print 'Getting features with Lasso...'\n",
    "    lasso = LassoCV().fit(X, y)\n",
    "    lasso_coefs = lasso.coef_\n",
    "    print 'Lasso Alpha', lasso.alpha_\n",
    "    for features, coefs in zip(X.columns, lasso_coefs):\n",
    "        if coefs > 0:\n",
    "            selectedFeatures.append(features)\n",
    "    return selectedFeatures\n",
    "\n",
    "trainSet = transformData(trainTable,encoder = 'LabelEncoder', nanFillStrategy = 'zero')\n",
    "holdoutSet = transformData(holdoutTable, encoder = 'LabelEncoder', nanFillStrategy = 'zero')\n",
    "selectedFeatures = lassoStrategy(trainSet.iloc[:, :-1], trainSet['label'])\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42).fit(trainSet[selectedFeatures], trainSet['label'],\n",
    "        sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "preds = clf.predict(holdoutSet[selectedFeatures])\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table was transformed!\n",
      "table was transformed!\n",
      "Confusion Matrix\n",
      "[[4932 2447]\n",
      " [ 184  437]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.686043476733\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.67      0.79      7379\n",
      "          1       0.15      0.70      0.25       621\n",
      "\n",
      "avg / total       0.90      0.67      0.75      8000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Top correlated Features\n",
    "trainSet = transformData(trainTable, \n",
    "                         catColumns = maxCorrCatFeatures, \n",
    "                         encoder = 'LabelEncoder', nanFillStrategy = 'zero')\n",
    "holdoutSet = transformData(holdoutTable, \n",
    "                         catColumns = maxCorrCatFeatures, \n",
    "                         encoder = 'LabelEncoder', nanFillStrategy = 'zero')\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42).fit(trainSet.iloc[:,:-1], trainSet['label'],\n",
    "        sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "preds = clf.predict(holdoutSet.iloc[:, :-1])\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table was transformed!\n",
      "table was transformed!\n"
     ]
    }
   ],
   "source": [
    "trainSet = transformData(trainTable, encoder = 'LabelEncoder', \n",
    "                         catColumns = maxCorrCatFeatures,nanFillStrategy = 'zero')\n",
    "holdoutSet = transformData(holdoutTable, encoder = 'LabelEncoder', \n",
    "                           catColumns = maxCorrCatFeatures, nanFillStrategy = 'zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала запустим Градиентный бустинг со стандартными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[4932 2447]\n",
      " [ 184  437]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.686043476733\n",
      "Recall = 0.703703703704\n",
      "Precision = 0.151525658807\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.96      0.67      0.79      7379\n",
      "          1       0.15      0.70      0.25       621\n",
      "\n",
      "avg / total       0.90      0.67      0.75      8000\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 54.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "baseline = GradientBoostingClassifier(random_state=42)\n",
    "baseline.fit(trainSet.iloc[:, :-1],trainSet['label'], \n",
    "             sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "preds = baseline.predict(holdoutSet.iloc[:, :-1])\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print \"Recall = {0}\".format(recall_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print \"Precision = {0}\".format(precision_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p_test1 = {'learning_rate':[0.15, 0.01, 0.001], \n",
    "           'n_estimators':[100,250,500, 750]}\n",
    "tuning = GridSearchCV(estimator = GradientBoostingClassifier(random_state=42), \n",
    "                      param_grid = p_test1, \n",
    "                      scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "tuning.fit(trainSet.iloc[:, :-1],trainSet['label'], \n",
    "        sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "print tuning.best_params_, tuning.best_score_\n",
    "\n",
    "\n",
    "preds = tuning.predict(holdoutSet.iloc[:, :-1])\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print \"Recall = {0}\".format(recall_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print \"Precision = {0}\".format(precision_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2} 0.727515801815\n",
      "Confusion Matrix\n",
      "[[4085 3294]\n",
      " [ 135  486]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.668103372084\n",
      "Recall = 0.782608695652\n",
      "Precision = 0.128571428571\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.97      0.55      0.70      7379\n",
      "          1       0.13      0.78      0.22       621\n",
      "\n",
      "avg / total       0.90      0.57      0.67      8000\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 34min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_test2 = {'max_depth':[2,4,6]}\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(n_estimators=750, \n",
    "                                                            learning_rate = 0.01,\n",
    "                                                            random_state=42),       \n",
    "            param_grid = p_test2, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "\n",
    "tuning.fit(trainSet.iloc[:, :-1],trainSet['label'], \n",
    "        sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "print tuning.best_params_, tuning.best_score_\n",
    "\n",
    "preds = tuning.predict(holdoutSet.iloc[:, :-1])\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print \"Recall = {0}\".format(recall_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print \"Precision = {0}\".format(precision_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор min_samples_split и min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 40, 'min_samples_leaf': 1} 0.727515945053\n",
      "Confusion Matrix\n",
      "[[4085 3294]\n",
      " [ 135  486]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.668103372084\n",
      "Recall = 0.782608695652\n",
      "Precision = 0.128571428571\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.97      0.55      0.70      7379\n",
      "          1       0.13      0.78      0.22       621\n",
      "\n",
      "avg / total       0.90      0.57      0.67      8000\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 40min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_test3 = {'min_samples_split':[2, 8, 40, 80], \n",
    "           'min_samples_leaf':[1, 3, 7]}\n",
    "\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.01, n_estimators=750,\n",
    "                                                            max_depth=2,random_state=42), \n",
    "            param_grid = p_test3, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "\n",
    "tuning.fit(trainSet.iloc[:, :-1],trainSet['label'], \n",
    "        sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "print tuning.best_params_, tuning.best_score_\n",
    "\n",
    "preds = tuning.predict(holdoutSet.iloc[:, :-1])\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print \"Recall = {0}\".format(recall_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print \"Precision = {0}\".format(precision_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2'} 0.703501985097\n",
      "Confusion Matrix\n",
      "[[6460  919]\n",
      " [ 411  210]]\n",
      "****************************************************************\n",
      "Roc-auc = 0.606810815128\n",
      "Recall = 0.338164251208\n",
      "Precision = 0.186005314438\n",
      "****************************************************************\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.94      0.88      0.91      7379\n",
      "          1       0.19      0.34      0.24       621\n",
      "\n",
      "avg / total       0.88      0.83      0.85      8000\n",
      "\n",
      "\n",
      "\n",
      "Wall time: 10min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_test4 = {'max_features':['auto','log2', None]}\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.15, n_estimators=750,\n",
    "                                                            min_samples_split=40, \n",
    "                                                            min_samples_leaf=1, \n",
    "                                                            random_state=42), \n",
    "param_grid = p_test4, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "tuning.fit(trainSet.iloc[:, :-1],trainSet['label'], \n",
    "        sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "print tuning.best_params_, tuning.best_score_\n",
    "\n",
    "preds = tuning.predict(holdoutSet.iloc[:, :-1])\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print \"Recall = {0}\".format(recall_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print \"Precision = {0}\".format(precision_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подбор subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "p_test5= {'subsample':[0.85, 0.95, 1]}\n",
    "tuning = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.15, n_estimators= 100,\n",
    "                                                            max_depth=4, min_samples_split=80, \n",
    "                                                            min_samples_leaf=1,max_features='auto' , \n",
    "                                                            random_state=42), \n",
    "                                    param_grid = p_test5, scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "tuning.fit(trainSet.iloc[:, :-1],trainSet['label'], \n",
    "        sample_weight = returnWeightedTarget(list(trainSet['label']), [0.5, 8]))\n",
    "print tuning.best_params_, tuning.best_score_\n",
    "\n",
    "preds = tuning.predict(holdoutSet.iloc[:, :-1])\n",
    "\n",
    "print \"Confusion Matrix\"\n",
    "print confusion_matrix(holdoutSet['label'], preds)\n",
    "print '*' * 64\n",
    "print \"Roc-auc = {0}\".format(roc_auc_score(holdoutSet['label'], preds))\n",
    "print \"Recall = {0}\".format(recall_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print \"Precision = {0}\".format(precision_score(holdoutSet['label'], preds, average = 'binary'))\n",
    "print '*' * 64\n",
    "print \"Classification Report\"\n",
    "print classification_report(holdoutSet['label'], preds)\n",
    "print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors=list(trainSet.iloc[:, :-1])\n",
    "feat_imp = pd.Series(tuning.feature_importances_, predictors).sort_values(ascending=False)[:15]\n",
    "feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print confusion_matrix(holdoutSet['label'], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
